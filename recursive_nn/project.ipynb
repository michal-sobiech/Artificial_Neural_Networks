{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "aWMQUyFCy6G5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.utils.data as data\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7v8742QzBNg",
        "outputId": "45c8ffc6-9174-44fb-c003-0a2baaa32a97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# device = torch.device('cpu')\n",
        "device = torch.device('cuda')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_SVoBWkr5Nq",
        "outputId": "923f408f-b707-4d8b-c6e5-551c657e8cfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load from Google Drive\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    file_path = '/content/drive/My Drive/ssne/train.pkl'\n",
        "    test_path = '/content/drive/My Drive/ssne/test_no_target.pkl'\n",
        "\n",
        "    print('Successfully loaded from Google Drive')\n",
        "\n",
        "except Exception:\n",
        "\n",
        "    file_path = 'train.pkl'\n",
        "    test_path = 'test_no_target.pkl'\n",
        "\n",
        "    print('Failed to load from Google Drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "VuZZ_n0KzQyE"
      },
      "outputs": [],
      "source": [
        "with open(file_path, 'rb') as handle:\n",
        "    train_data_raw = pickle.load(handle)\n",
        "\n",
        "with open(test_path, 'rb') as handle:\n",
        "    test_data = pickle.load(handle)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zmpXNb-04vq8"
      },
      "source": [
        "# Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "SdAg2Xkm4p7f"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "def pad_collate(batch, pad_value=0):\n",
        "    xx, yy = zip(*batch)\n",
        "\n",
        "    x_lens = [len(x) for x in xx]\n",
        "    y_lens = [len(y) for y in yy]\n",
        "\n",
        "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=pad_value)\n",
        "    yy_stacked = torch.stack(yy)\n",
        "\n",
        "    return xx_pad, yy_stacked, x_lens, y_lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "GQ5cR2xo9n1G"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "split = 0.8\n",
        "\n",
        "train_set_size = int(split * len(train_data_raw))\n",
        "val_set_size = len(train_data_raw) - train_set_size\n",
        "\n",
        "train_set_raw, val_set_raw = data.random_split(\n",
        "    train_data_raw,\n",
        "    [train_set_size, val_set_size]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "OKSrEUCEChK7"
      },
      "outputs": [],
      "source": [
        "class_count = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gn1ctXCmyhll"
      },
      "source": [
        "## Train data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "sIOrq97FV4G2"
      },
      "outputs": [],
      "source": [
        "train_xx = []\n",
        "train_yy = []\n",
        "\n",
        "for x, y in train_set_raw:\n",
        "    train_xx.append(torch.tensor(x))\n",
        "    train_yy.append(F.one_hot(torch.tensor(y), class_count))\n",
        "\n",
        "train_set = [(x, y) for x, y in zip(train_xx, train_yy)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eHdPY9KAyjb7"
      },
      "source": [
        "## Validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "jVzVJkvWV3Dy"
      },
      "outputs": [],
      "source": [
        "val_xx = []\n",
        "val_yy = []\n",
        "\n",
        "for x, y in val_set_raw:\n",
        "    val_xx.append(torch.tensor(x))\n",
        "    val_yy.append(F.one_hot(torch.tensor(y), class_count))\n",
        "\n",
        "val_set = [(x, y) for x, y in zip(val_xx, val_yy)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDgsm32CQtnC"
      },
      "source": [
        "# Test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "HgXmLChO1FL5"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class TestDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "0MB-JGGjQ1qV"
      },
      "outputs": [],
      "source": [
        "# Funkcja pad_collate do wyrównania sekwencji\n",
        "def pad_collate_for_test(batch):\n",
        "    sequences = [torch.tensor(seq) for seq in batch]\n",
        "    # Padding sekwencji\n",
        "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=0)\n",
        "    # Tensor długości sekwencji\n",
        "    lengths = torch.tensor([len(seq) for seq in sequences])\n",
        "    return padded_sequences, lengths"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fMj-mpqFq4J"
      },
      "source": [
        "# Take into account the imbalance of classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6sVCLBGGEOr",
        "outputId": "950c3c92-cc1b-4ef9-fa1c-138d6a48818d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 1309, 1: 381, 2: 122, 3: 344, 4: 195}\n"
          ]
        }
      ],
      "source": [
        "classes = list(range(class_count))\n",
        "\n",
        "class_occurence_count = {cls: 0 for cls in classes}\n",
        "\n",
        "def one_hot_decode(encoding):\n",
        "    return torch.argmax(encoding).item()\n",
        "\n",
        "for y in train_yy:\n",
        "    y_decoded = one_hot_decode(y)\n",
        "    class_occurence_count[y_decoded] += 1\n",
        "\n",
        "print(class_occurence_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQTu6XX8PJjb",
        "outputId": "18d05409-6d70-48a4-b52c-88584a059acb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 75, 1: 150, 2: 275, 3: 245, 4: 275}\n"
          ]
        }
      ],
      "source": [
        "# weights = {cls : 1.0 / class_occurence_count[cls] for cls in class_occurence_count.keys()}\n",
        "weights = {0: 75, 1: 150, 2: 275, 3: 245, 4: 275}\n",
        "print(weights)\n",
        "\n",
        "y_weights = [weights[one_hot_decode(y)] for y in train_yy]\n",
        "y_weights = torch.tensor(y_weights)\n",
        "\n",
        "sampler = data.WeightedRandomSampler(weights=y_weights, num_samples=len(y_weights))\n",
        "\n",
        "train_dloader = data.DataLoader(\n",
        "    train_set,\n",
        "    sampler=sampler,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "\n",
        "val_dloader = data.DataLoader(\n",
        "    val_set,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2,\n",
        "    collate_fn=pad_collate\n",
        ")\n",
        "test_dataset = TestDataset(test_data)\n",
        "\n",
        "test_dloader = data.DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=2,\n",
        "    collate_fn=pad_collate_for_test\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et7TwHhxUmhs"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "PCyVu2FCUi0V"
      },
      "outputs": [],
      "source": [
        "class LstmClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_layers = 1\n",
        "        self.hidden_size = 64\n",
        "\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=1,\n",
        "            hidden_size=self.hidden_size,\n",
        "            num_layers=self.num_layers\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Sequential(\n",
        "            nn.Linear(self.hidden_size, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 5),\n",
        "        )\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        state = torch.zeros(self.num_layers, batch_size, self.hidden_size)\n",
        "        return hidden, state\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        x = torch.transpose(x, 0, 1)\n",
        "        all_outputs, hidden = self.lstm(x, hidden)\n",
        "        out = all_outputs[-1]\n",
        "        x = self.linear(out)\n",
        "        return x, hidden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "IRrjfTwbW9tm"
      },
      "outputs": [],
      "source": [
        "model = LstmClassifier().to(device)\n",
        "loss_fun = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Y512kyJXXmi"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elNnY2cbXZNM",
        "outputId": "7abd0b2b-b8e7-4b3a-da4e-0394986b57fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0, loss: 57.6282749\n",
            "Epoch: 10, loss: 56.5606825\n",
            "Epoch: 20, loss: 56.7194697\n",
            "Epoch: 30, loss: 56.4044673\n",
            "Epoch: 40, loss: 56.1349300\n",
            "Epoch: 50, loss: 56.7503422\n",
            "Epoch: 60, loss: 56.0696146\n",
            "Epoch: 70, loss: 56.1365284\n",
            "Epoch: 80, loss: 56.4641567\n",
            "Epoch: 90, loss: 55.9011843\n",
            "Epoch: 100, loss: 55.3892013\n",
            "Epoch: 110, loss: 54.5438774\n",
            "Epoch: 120, loss: 55.6352043\n",
            "Epoch: 130, loss: 54.8349533\n",
            "Epoch: 140, loss: 54.3642347\n",
            "Epoch: 150, loss: 54.9541868\n",
            "Epoch: 160, loss: 54.7391346\n",
            "Epoch: 170, loss: 54.4955227\n",
            "Epoch: 180, loss: 54.5583125\n",
            "Epoch: 190, loss: 53.9115940\n",
            "Epoch: 200, loss: 54.1150939\n",
            "Epoch: 210, loss: 54.8716518\n",
            "Epoch: 220, loss: 54.2924843\n",
            "Epoch: 230, loss: 54.0169945\n",
            "Epoch: 240, loss: 55.1207857\n",
            "Epoch: 250, loss: 53.6280262\n",
            "Epoch: 260, loss: 52.7944185\n",
            "Epoch: 270, loss: 53.2416140\n",
            "Epoch: 280, loss: 53.1874624\n",
            "Epoch: 290, loss: 52.2048815\n",
            "Epoch: 300, loss: 53.1951106\n",
            "Epoch: 310, loss: 52.3710210\n",
            "Epoch: 320, loss: 52.4750799\n",
            "Epoch: 330, loss: 51.5421333\n",
            "Epoch: 340, loss: 52.7118049\n",
            "Epoch: 350, loss: 52.3239080\n",
            "Epoch: 360, loss: 52.2692040\n",
            "Epoch: 370, loss: 51.1341655\n",
            "Epoch: 380, loss: 52.0807854\n",
            "Epoch: 390, loss: 51.6604807\n",
            "Epoch: 400, loss: 52.5774860\n",
            "Epoch: 410, loss: 51.5376754\n",
            "Epoch: 420, loss: 51.3798642\n",
            "Epoch: 430, loss: 49.7450442\n",
            "Epoch: 440, loss: 50.3399568\n",
            "Epoch: 450, loss: 49.8715589\n",
            "Epoch: 460, loss: 50.6594181\n",
            "Epoch: 470, loss: 48.4993410\n",
            "Epoch: 480, loss: 47.7386094\n",
            "Epoch: 490, loss: 48.5019026\n",
            "Epoch: 500, loss: 48.2764764\n",
            "Epoch: 510, loss: 46.7185436\n",
            "Epoch: 520, loss: 46.5905696\n",
            "Epoch: 530, loss: 47.2554195\n",
            "Epoch: 540, loss: 49.9199845\n",
            "Epoch: 550, loss: 47.4239650\n",
            "Epoch: 560, loss: 46.7299312\n",
            "Epoch: 570, loss: 46.1141911\n",
            "Epoch: 580, loss: 45.2735181\n",
            "Epoch: 590, loss: 46.0221884\n",
            "Epoch: 600, loss: 47.9239246\n",
            "Epoch: 610, loss: 45.2155621\n",
            "Epoch: 620, loss: 44.4142004\n",
            "Epoch: 630, loss: 45.4885124\n",
            "Epoch: 640, loss: 43.8939502\n",
            "Epoch: 650, loss: 52.2016385\n",
            "Epoch: 660, loss: 50.5042292\n",
            "Epoch: 670, loss: 51.2928262\n",
            "Epoch: 680, loss: 51.4139045\n",
            "Epoch: 690, loss: 49.2169089\n",
            "Epoch: 700, loss: 56.9804871\n",
            "Epoch: 710, loss: 56.1548297\n",
            "Epoch: 720, loss: 56.2641524\n",
            "Epoch: 730, loss: 55.0794984\n",
            "Epoch: 740, loss: 54.5636731\n",
            "Epoch: 750, loss: 54.7506830\n",
            "Epoch: 760, loss: 54.5152311\n",
            "Epoch: 770, loss: 54.2496853\n",
            "Epoch: 780, loss: 53.9914254\n",
            "Epoch: 790, loss: 54.7213176\n",
            "Epoch: 800, loss: 54.5411659\n",
            "Epoch: 810, loss: 54.4451514\n",
            "Epoch: 820, loss: 52.5678452\n",
            "Epoch: 830, loss: 53.8320290\n",
            "Epoch: 840, loss: 54.5340122\n",
            "Epoch: 850, loss: 53.0686042\n",
            "Epoch: 860, loss: 53.2722753\n",
            "Epoch: 870, loss: 52.0076772\n",
            "Epoch: 880, loss: 46.5007550\n",
            "Epoch: 890, loss: 43.6864542\n",
            "Epoch: 900, loss: 41.8449395\n",
            "Epoch: 910, loss: 40.5354962\n",
            "Epoch: 920, loss: 43.7149643\n",
            "Epoch: 930, loss: 37.7663257\n",
            "Epoch: 940, loss: 36.7926472\n",
            "Epoch: 950, loss: 34.8783479\n",
            "Epoch: 960, loss: 31.6524906\n",
            "Epoch: 970, loss: 30.2328773\n",
            "Epoch: 980, loss: 29.0282148\n",
            "Epoch: 990, loss: 28.8044618\n",
            "Epoch: 1000, loss: 28.3163131\n",
            "Epoch: 1010, loss: 29.6972236\n",
            "Epoch: 1020, loss: 31.4332085\n",
            "Epoch: 1030, loss: 28.4109810\n",
            "Epoch: 1040, loss: 25.1487824\n",
            "Epoch: 1050, loss: 23.9569816\n",
            "Epoch: 1060, loss: 25.1790229\n",
            "Epoch: 1070, loss: 22.2086393\n",
            "Epoch: 1080, loss: 21.9569750\n",
            "Epoch: 1090, loss: 21.3851123\n",
            "Epoch: 1100, loss: 20.7738742\n",
            "Epoch: 1110, loss: 27.5315761\n",
            "Epoch: 1120, loss: 20.7083189\n",
            "Epoch: 1130, loss: 19.8942132\n",
            "Epoch: 1140, loss: 17.8862431\n",
            "Epoch: 1150, loss: 17.4555411\n",
            "Epoch: 1160, loss: 15.4448919\n",
            "Epoch: 1170, loss: 14.0448342\n",
            "Epoch: 1180, loss: 25.6272624\n",
            "Epoch: 1190, loss: 15.1528022\n",
            "Epoch: 1200, loss: 12.9975136\n",
            "Epoch: 1210, loss: 14.3546008\n",
            "Epoch: 1220, loss: 11.7477896\n",
            "Epoch: 1230, loss: 10.1982324\n",
            "Epoch: 1240, loss: 10.2239463\n",
            "Epoch: 1250, loss: 8.5992471\n",
            "Epoch: 1260, loss: 8.0652693\n",
            "Epoch: 1270, loss: 8.8068093\n",
            "Epoch: 1280, loss: 8.4048390\n",
            "Epoch: 1290, loss: 7.8676276\n",
            "Epoch: 1300, loss: 8.7604877\n",
            "Epoch: 1310, loss: 6.4132506\n",
            "Epoch: 1320, loss: 7.1062961\n",
            "Epoch: 1330, loss: 7.5940561\n",
            "Epoch: 1340, loss: 6.1574471\n",
            "Epoch: 1350, loss: 7.3390912\n",
            "Epoch: 1360, loss: 5.6641312\n",
            "Epoch: 1370, loss: 4.8353073\n",
            "Epoch: 1380, loss: 6.4588971\n",
            "Epoch: 1390, loss: 6.0804217\n",
            "Epoch: 1400, loss: 5.3664044\n",
            "Epoch: 1410, loss: 8.0692254\n",
            "Epoch: 1420, loss: 7.6646877\n",
            "Epoch: 1430, loss: 5.0272664\n",
            "Epoch: 1440, loss: 6.0089084\n",
            "Epoch: 1450, loss: 3.9552669\n",
            "Epoch: 1460, loss: 7.5659206\n",
            "Epoch: 1470, loss: 12.7659619\n",
            "Epoch: 1480, loss: 9.0327734\n",
            "Epoch: 1490, loss: 8.9140545\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 1500\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "    loss_sum = 0.0\n",
        "    for x, y, x_len, y_len in train_dloader:\n",
        "\n",
        "        model.train()\n",
        "\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        x = x.unsqueeze(2)\n",
        "        x = x.float()\n",
        "        y = y.float()\n",
        "\n",
        "        hidden, state = model.init_hidden(x.size(0))\n",
        "        hidden, state = hidden.to(device), state.to(device)\n",
        "\n",
        "        preds, _ = model.forward(x, (hidden, state))\n",
        "\n",
        "        preds.squeeze(1)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss = loss_fun(preds, y)\n",
        "        loss_sum += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch: {epoch}, loss: {loss_sum:.7f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u6uBwmvWHn0E"
      },
      "source": [
        "# Validate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN3J2pbGHnMO",
        "outputId": "e54dd535-b9e1-4fec-e51e-4b10caddb392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class 0 accuracy: 0.87539\n",
            "Class 1 accuracy: 0.52577\n",
            "Class 2 accuracy: 0.25000\n",
            "Class 3 accuracy: 0.69072\n",
            "Class 4 accuracy: 0.78049\n",
            "Total accuracy: 0.74660\n"
          ]
        }
      ],
      "source": [
        "correct_preds = {cls: 0 for cls in classes}\n",
        "all_preds = {cls: 0 for cls in classes}\n",
        "\n",
        "for x, y, x_len, y_len in val_dloader:\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    x = x.unsqueeze(2)\n",
        "    x = x.float()\n",
        "    y = y.float()\n",
        "\n",
        "    hidden, state = model.init_hidden(x.size(0))\n",
        "    hidden, state = hidden.to(device), state.to(device)\n",
        "\n",
        "    preds, _ = model.forward(x, (hidden, state))\n",
        "    preds.squeeze(1)\n",
        "\n",
        "    predicted_classes = torch.argmax(preds, dim=1)\n",
        "    actual_classes = torch.argmax(y, dim=1)\n",
        "\n",
        "    for predicted, actual in zip(predicted_classes, actual_classes):\n",
        "        all_preds[actual.item()] += 1\n",
        "\n",
        "        if predicted == actual:\n",
        "            correct_preds[actual.item()] += 1\n",
        "\n",
        "for cls in classes:\n",
        "    accuracy = float(correct_preds[cls]) / float(all_preds[cls])\n",
        "    print(f'Class {cls} accuracy: {accuracy:.5f}')\n",
        "\n",
        "total_accuracy = float(sum(correct_preds.values())) / float(sum(all_preds.values()))\n",
        "print(f'Total accuracy: {total_accuracy:.5f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Uvl_dibw4Xg"
      },
      "source": [
        "Dla wag wyliczanych wzorem \"1 / liczba wystąpień klasy\" wyniki były niezadowalające, accuracy oscylowało w okolicach 55%. Dlatego postanowiliśmy poeksperymentać z ręcznie ustawianymi wagami klas. Staraliśmy się dobierać je w oparciu o accuracy dla poszczególnych klas. Poniżej kilka ostatnich rezultatów:\n",
        "\n",
        "Batch size: 64, liczba epok 1500\n",
        "\n",
        " - dla wag: {0: 70, 1: 130, 2: 270, 3: 230, 4: 260} total accuracy: 0.71599\n",
        " - dla wag: {0: 70, 1: 140, 2: 280, 3: 250, 4: 270} total accuracy: 0.71769\n",
        " - dla wag: {0: 90, 1: 150, 2: 275, 3: 245, 4: 275} total accuracy: 0.73200\n",
        " - dla wag: {0: 75, 1: 150, 2: 275, 3: 245, 4: 275} total accuracy: 0.74660"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUOUIB0hOAjR",
        "outputId": "a3bac86f-ea22-47ba-be60-9893232af46c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "18\n",
            "[2 2 0 0 0 0 3 0 0 2 0 0 0 1 0 0 0 0 3 0 0 1 0 0 1 0 0 0 1 0 0 4 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 3 0 0 1 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0 1 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 1 0 0 3 0 1 3 0 0 0 1 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 3 0 0 0 0 0 0 0 0 0 0 0 1 0 3 0 3 0 2 0 0 3 0 0 3 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "[0 0 0 0 3 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0 3 3 0 0 0\n",
            " 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 3 4 0 0 0 0 0 0 0]\n",
            "[0 0 1 0 0 0 3 1 0 3 0 0 0 0 0 0 0 0 1 0 0 0 3 1 2 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 2 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 4 1 0 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 3 0 0 0 0 0 0 0 3 0 0 3 0 3 3 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 1 0 0 3 1 0 4 3 0 4 0 0 0 4 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 4 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "[0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 0 0 0 0\n",
            " 1 0 0 1 1 0 1 0 1 0 0 0 1 1 1 0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[1 0 0 3 0 0 1 1 4 0 1 1 1 1 0 4 0 1 1 0 1 0 0 0 1 0 0 3 0 0 0 2 0 1 1 1 0\n",
            " 2 1 1 0 1 2 1 3 0 1 1 1 1 3 1 3 2 0 0 0 3 1 3 0 3 1 1]\n",
            "[0 1 1 1 3 3 3 1 0 1 2 0 0 1 1 0 1 0 1 2 2 0 1 1 0 0 1 1 3 0 0 0 1 1 1 1 2\n",
            " 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 3 1 1 1 0 1 1 1 1 1 2 1]\n",
            "[0 1 1 1 0 0 0 1 1 1 0 0 1 1 2 1 1 0 1 1 1 1 1 1 1 0 1 0 0 1 2 0 0 0 3 1 2\n",
            " 2 2 2 3 0 2 0 3 1 0 0 1 3 2 2 3 3 3 2 3 3 1 2 0 2 0 0]\n",
            "[2 0 0 4 3 0 0 0 3 2 0 0 3 0 1 1 2 4 0 3 2 3 3 3 4 4 0 3 0 4 3 0 0 0 0 3 0\n",
            " 3 3 3 4 3 2 3 4 2 0 3 4 3 3 3 0 2 3 3 2 3 3 3 0 3 3 0]\n",
            "[1 0 3 0 3 3 0 0 3 3 3 3 3 3 0 3 0 3 3 3 2 3 3 3 3 0 0 0 0 3 3 3 3 3 3 0 2\n",
            " 3 0 3 3 0 0 3 4 3 3 3 0 0 3 3 2 3 3 3 1 0 3 0 0 0 3 3]\n",
            "[3 3 3 2 0 3 3 0 0 3 0 4 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 0 3 3 2\n",
            " 3 3 3 3 0 3 0 0 3 4 3 4 4 4 4 4 4 4 4 0 4 4 1 4 4 4 1]\n",
            "[1 4 4 0 4 0 4 4 4 4 4 4 4 4 4 4 4 4 4 0 4 4 4 4 4 4 0 4 0 4 4 4 4 0 3 4 4\n",
            " 4 4 4 4 4 3 4 4 4 4 4 3 4 4 0 0 4 4 4 3 3 3 0 4 4 4 4]\n",
            "[4 4 4 4 3 4 3 4 4 0 4 4 4 4 4]\n"
          ]
        }
      ],
      "source": [
        "combined_preds = np.empty((0,))\n",
        "\n",
        "print(len(test_dloader))\n",
        "for features, _ in test_dloader:\n",
        "    model.eval()\n",
        "\n",
        "    features = features.to(device)\n",
        "    features = features.unsqueeze(2)\n",
        "    features = features.float()\n",
        "\n",
        "    hidden, state = model.init_hidden(features.size(0))\n",
        "    hidden, state = hidden.to(device), state.to(device)\n",
        "\n",
        "    preds, _ = model.forward(features, (hidden, state))\n",
        "    preds.squeeze(1)\n",
        "\n",
        "    predicted_classes = torch.argmax(preds, dim=1)\n",
        "    preds_np = predicted_classes.detach().cpu().numpy()\n",
        "    print(preds_np)\n",
        "    combined_preds = np.concatenate((combined_preds, preds_np)).astype(int)\n",
        "np.savetxt('piatek_Kubiszyn_Sobiech.csv', combined_preds, delimiter=',', fmt='%d')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'model.pth')"
      ],
      "metadata": {
        "id": "zhU5sFxdC3RN"
      },
      "execution_count": 69,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}